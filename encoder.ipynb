{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten\n",
    "\n",
    "from transformer.encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'num_heads': 12, \n",
    "          'vocab_size': 30522,\n",
    "          'hidden_size': 128,\n",
    "          'max_position_embeds': 512,\n",
    "          'intermediate_size': 512,\n",
    "          'dropout_p': 0.1,\n",
    "          'input_size': (100,),\n",
    "          'num_hidden_layers': 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some toy data\n",
    "\n",
    "The yelp sentence sentiment data set from Kaggle will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "with open('yelp_labelled.txt', 'r') as FILE:\n",
    "    while True:\n",
    "        row = FILE.readline()\n",
    "        if not row:\n",
    "            break\n",
    "        row = row.strip().split('\\t')\n",
    "        sentence = row[0]\n",
    "        sentiment = int(row[1])\n",
    "        rows.append({'sentence': sentence, 'sentiment': sentiment})\n",
    " \n",
    "df = pd.DataFrame(rows, columns=['sentence', 'sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our toy vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<pad>': 0, '<unk>': 1}\n",
    "index = 2\n",
    "for s in df['sentence'].values:\n",
    "    words = s.strip().split()\n",
    "    for word in words:\n",
    "        i = vocab.get(word)\n",
    "        if i is None:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "\n",
    "vocab_reverse = {value: key for key, value in vocab.items()}\n",
    "\n",
    "config['vocab_size'] = len(vocab)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the sentences and split into x and y \n",
    "\n",
    "y will be the last token of each sequence, so we can try to predict it. But mostly we just want to see if our transformer encoder trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n",
      "Vocabulary size: 2971\n",
      "Max sentence length: 31\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sent):\n",
    "    tokens = [vocab[word] for word in sent.strip().split()]\n",
    "    return tokens\n",
    "\n",
    "tokens = list(map(tokenize, df['sentence']))\n",
    "x = [s[:-1] for s in tokens]\n",
    "x = tf.keras.utils.pad_sequences(x)\n",
    "y = np.array([s[-1] for s in tokens])\n",
    "\n",
    "config['input_size'] = (len(x[0]),)\n",
    "\n",
    "print(f'Number of sentences: {df.shape[0]}')\n",
    "print(f'Vocabulary size: {config[\"vocab_size\"]}')\n",
    "print(f'Max sentence length: {config[\"input_size\"][0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our transformer!\n",
    "\n",
    "We'll just train our encoder by the task of predicting the last word of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder (Encoder)           (None, 31, 128)           640232    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3968)              0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 2971)              11791899  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,432,131\n",
      "Trainable params: 12,432,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf = Sequential([InputLayer(input_shape=config['input_size']),\n",
    "                  Encoder(config),\n",
    "                  Flatten(),\n",
    "                  Dense(config['vocab_size'], activation='softmax')])\n",
    "\n",
    "clf.build()\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 21s 176ms/step - loss: 7.7236\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 5.9817\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 4.8921\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 2.7039\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.9982\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4295\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.2661\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.1738\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.1169\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0855\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0812\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0710\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0546\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.0565\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.0798\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0491\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0581\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0588\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0625\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.0526\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0414\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.0326\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0648\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0487\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0431\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.0333\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0400\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0427\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0378\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0478\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0362\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0440\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0509\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0439\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0404\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0418\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0400\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0473\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0553\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0356\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0317\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0346\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0583\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0539\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0756\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.0859\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0867\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.1048\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.1061\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 6s 173ms/step - loss: 0.1186\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.1040\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0910\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.0781\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0898\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0733\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0777\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.0668\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.0503\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0612\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0689\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0561\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0765\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0637\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0627\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0629\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0637\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.0752\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.0684\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0599\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0494\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 0.0594\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.0378\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 6s 173ms/step - loss: 0.0767\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0435\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0350\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.0307\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0574\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0523\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0523\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0321\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0384\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.0481\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0462\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0407\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.0258\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.0488\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0602\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0567\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0267\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0403\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 6s 180ms/step - loss: 0.0362\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0335\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0449\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.0594\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0626\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0495\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.0715\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.0350\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 6s 175ms/step - loss: 0.0379\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0314\n"
     ]
    }
   ],
   "source": [
    "clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "hist = clf.fit(x, \n",
    "               y,\n",
    "               epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our toy model\n",
    "\n",
    "Make up a few sentences that may belong to the distribution (Yelp restaraunt review sentences).\n",
    "\n",
    "Then, dropping off that last word of each, try to complete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Original sentence: It really tasted awful.\n",
      "Completed sentence: It really tasted dirt.\n",
      "Literal match: False\n",
      "\n",
      "Original sentence: It was very good.\n",
      "Completed sentence: It was very good.\n",
      "Literal match: True\n",
      "\n",
      "Original sentence: It was awful.\n",
      "Completed sentence: It was packed!!\n",
      "Literal match: False\n",
      "\n",
      "Original sentence: This is a very bad place.\n",
      "Completed sentence: This is a very bad chef.\n",
      "Literal match: False\n",
      "\n",
      "Original sentence: The spaghetti was perfect\n",
      "Completed sentence: The spaghetti was meh.\n",
      "Literal match: False\n",
      "\n",
      "Original sentence: The eggs were gross!\n",
      "Completed sentence: The eggs were good.\n",
      "Literal match: False\n",
      "\n",
      "Original sentence: My steak was bad.\n",
      "Completed sentence: My steak was delicious!\n",
      "Literal match: False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = [\"It really tasted awful.\",\n",
    "     \"It was very good.\",\n",
    "     \"It was awful.\",\n",
    "     \"This is a very bad place.\",\n",
    "     \"The spaghetti was perfect\",\n",
    "     \"The eggs were gross!\",\n",
    "     \"My steak was bad.\"]\n",
    "\n",
    "# Tokenize our sentence, separate last word, and pad\n",
    "tokens = list(map(tokenize, s))\n",
    "x = [s[:-1] for s in tokens]\n",
    "x = tf.keras.utils.pad_sequences(x, maxlen=config['input_size'][0])\n",
    "y = np.array([s[-1] for s in tokens])\n",
    "\n",
    "# Predict last word\n",
    "y_hat = clf.predict(x)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "matches = []\n",
    "for i in range(len(s)):\n",
    "     # construct predicted complete sentence\n",
    "     pred_s = x[i].tolist()\n",
    "     pred_s.append(y_hat[i])\n",
    "\n",
    "     #unpad\n",
    "     pred_s = [token for token in pred_s if token!= 0]\n",
    "\n",
    "     pred_s = ' '.join([vocab_reverse[i] for i in pred_s])\n",
    "     match = s[i] == pred_s\n",
    "     matches.append(match)\n",
    "     print(f'Original sentence: {s[i]}\\nCompleted sentence: {pred_s}\\nLiteral match: {match}\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
