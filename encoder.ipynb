{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling1D\n",
    "\n",
    "from transformer.encoder import Encoder\n",
    "from transformer.utils import WordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'num_heads': 12, \n",
    "          'vocab_size': 30522,\n",
    "          'hidden_size': 128,\n",
    "          'max_position_embeds': 512,\n",
    "          'intermediate_size': 512,\n",
    "          'dropout_p': 0.1,\n",
    "          'input_size': 100,\n",
    "          'num_hidden_layers': 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some toy data\n",
    "\n",
    "The yelp sentence sentiment data set from Kaggle will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "with open('yelp_labelled.txt', 'r') as FILE:\n",
    "    while True:\n",
    "        row = FILE.readline()\n",
    "        if not row:\n",
    "            break\n",
    "        row = row.strip().split('\\t')\n",
    "        sentence = row[0]\n",
    "        sentiment = int(row[1])\n",
    "        rows.append({'sentence': sentence, 'sentiment': sentiment})\n",
    " \n",
    "df = pd.DataFrame(rows, columns=['sentence', 'sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the sentences and split into x and y \n",
    "\n",
    "y will be the last token of each sequence, so we can try to predict it. But mostly we just want to see if our transformer encoder trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n",
      "Vocabulary size: 2971\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordTokenizer(make_mask=True)\n",
    "config['vocab_size'] = tokenizer.fit(df['sentence'].values)\n",
    "tokens, masks = tokenizer.transform(df['sentence'].values,\n",
    "                             max_len=config['input_size'])\n",
    "\n",
    "X = np.array([s[:-1] for s in tokens])\n",
    "y = np.array([s[-1] for s in tokens])\n",
    "masks = np.array(masks[:, :-1])\n",
    "\n",
    "print(f'Number of sentences: {df.shape[0]}')\n",
    "print(f'Vocabulary size: {config[\"vocab_size\"]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our transformer!\n",
    "\n",
    "We'll just train our encoder by the task of predicting the last word of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 99)]         0           []                               \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 99)]         0           []                               \n",
      "                                                                                                  \n",
      " Encoder (Encoder)              (None, 99, 128)      640232      ['input_9[0][0]',                \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 128)         0           ['Encoder[0][0]']                \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_199 (Dense)              (None, 2971)         383259      ['global_average_pooling1d_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,023,491\n",
      "Trainable params: 1,023,491\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "token_input = Input(shape=(config['input_size'] - 1,))\n",
    "mask_input = Input(shape=(config['input_size'] - 1,))\n",
    "x = Encoder(config)([token_input, mask_input])\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "output = Dense(config['vocab_size'], activation='softmax')(x)\n",
    "\n",
    "clf = Model(inputs=[token_input, mask_input], outputs=output)\n",
    "\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 20s 155ms/step - loss: 2.0107\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 1.1094\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.6771\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.4675\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.4020\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.3178\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.2863\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1978\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.2552\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.2517\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.2276\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.2037\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.2273\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.1748\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1731\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.1959\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.1586\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.1632\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 0.1604\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1915\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.1398\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.1326\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.1240\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.1047\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0865\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.1579\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.1060\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.1077\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.1110\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.1041\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.1264\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.0918\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0991\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.0961\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 0.1036\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.1354\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.1403\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.1163\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.1059\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.1083\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0967\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.1503\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.1458\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.1430\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1775\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.1600\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.1419\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.1423\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.1270\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.1173\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 5s 159ms/step - loss: 0.0866\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0681\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 6s 173ms/step - loss: 0.0850\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 0.0836\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0940\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 0.0853\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.1225\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 0.1067\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 0.0889\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.1039\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0726\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 0.0684\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0795\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0877\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.0800\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0926\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.0601\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.0536\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0733\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.0697\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0862\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.0901\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0838\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.0821\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.0733\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0779\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 6s 174ms/step - loss: 0.0556\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 0.0717\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 5s 163ms/step - loss: 0.0910\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.0750\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.1206\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.1197\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 6s 173ms/step - loss: 0.1325\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.1031\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0757\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.1154\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 5s 157ms/step - loss: 0.1125\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.1096\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.1047\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 5s 154ms/step - loss: 0.0922\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 5s 162ms/step - loss: 0.0762\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 5s 158ms/step - loss: 0.0562\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0847\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 0.1116\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 5s 155ms/step - loss: 0.0968\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0670\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0849\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.0757\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 0.0779\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.0727\n"
     ]
    }
   ],
   "source": [
    "clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "hist = clf.fit([X, masks],\n",
    "               y,\n",
    "               epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our toy model\n",
    "\n",
    "Make up a few sentences that may belong to the distribution (Yelp restaraunt review sentences).\n",
    "\n",
    "Then, dropping off that last word of each, try to complete them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Original sentence: It really tasted awful.\n",
      "Completed sentence: It really tasted though!\n",
      "\n",
      "Original sentence: It was very good.\n",
      "Completed sentence: It was very good.\n",
      "\n",
      "Original sentence: It was awful.\n",
      "Completed sentence: It was delicious!!!\n",
      "\n",
      "Original sentence: This is a very bad place.\n",
      "Completed sentence: This is a very bad Experience!\n",
      "\n",
      "Original sentence: The spaghetti was perfect\n",
      "Completed sentence: The spaghetti was amazing.\n",
      "\n",
      "Original sentence: The eggs were gross!\n",
      "Completed sentence: The eggs were amazing\n",
      "\n",
      "Original sentence: My steak was bad.\n",
      "Completed sentence: My steak was terrible!\n"
     ]
    }
   ],
   "source": [
    "s = [\"It really tasted awful.\",\n",
    "     \"It was very good.\",\n",
    "     \"It was awful.\",\n",
    "     \"This is a very bad place.\",\n",
    "     \"The spaghetti was perfect\",\n",
    "     \"The eggs were gross!\",\n",
    "     \"My steak was bad.\"]\n",
    "\n",
    "# Tokenize our sentence, separate last word, and pad\n",
    "tokens, masks = tokenizer.transform(s,\n",
    "                             max_len=config['input_size'])\n",
    "\n",
    "X_test = np.array([s[:-1] for s in tokens])\n",
    "y_test = np.array([s[-1] for s in tokens])\n",
    "masks_test = np.array(masks[:, :-1])\n",
    "\n",
    "# Predict last word\n",
    "y_hat = clf.predict([X_test, masks_test])\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "for i in range(len(s)):\n",
    "     # construct predicted complete sentence\n",
    "     pred_s = X_test[i].tolist()\n",
    "     pred_s.append(y_hat[i])\n",
    "\n",
    "     #unpad\n",
    "     pred_s = [token for token in pred_s if token!= 0]\n",
    "     pred_s = ' '.join([tokenizer.vocab_reverse[i] for i in pred_s])\n",
    "     print(f'\\nOriginal sentence: {s[i]}\\nCompleted sentence: {pred_s}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save encoder model\n",
    "\n",
    "Omitting the classifier head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 99), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\") at layer \"Encoder\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m encoder_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mModel(inputs\u001b[39m=\u001b[39;49mclf\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49minput,\n\u001b[0;32m      2\u001b[0m                                       outputs\u001b[39m=\u001b[39;49mclf\u001b[39m.\u001b[39;49mlayers[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49moutput)\n\u001b[0;32m      3\u001b[0m encoder_model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\karen\\myprojects\\my-transformer\\trans-env\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karen\\myprojects\\my-transformer\\trans-env\\lib\\site-packages\\keras\\engine\\functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m    159\u001b[0m         [\n\u001b[0;32m    160\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    161\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[0;32m    162\u001b[0m         ]\n\u001b[0;32m    163\u001b[0m     ):\n\u001b[0;32m    164\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    165\u001b[0m             inputs, outputs\n\u001b[0;32m    166\u001b[0m         )\n\u001b[1;32m--> 167\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\karen\\myprojects\\my-transformer\\trans-env\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karen\\myprojects\\my-transformer\\trans-env\\lib\\site-packages\\keras\\engine\\functional.py:266\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_coordinates\u001b[39m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[0;32m    265\u001b[0m \u001b[39m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[39m=\u001b[39m _map_graph_network(\n\u001b[0;32m    267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutputs\n\u001b[0;32m    268\u001b[0m )\n\u001b[0;32m    269\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_network_nodes \u001b[39m=\u001b[39m nodes\n\u001b[0;32m    270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nodes_by_depth \u001b[39m=\u001b[39m nodes_by_depth\n",
      "File \u001b[1;32mc:\\Users\\karen\\myprojects\\my-transformer\\trans-env\\lib\\site-packages\\keras\\engine\\functional.py:1142\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39mkeras_inputs):\n\u001b[0;32m   1141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(x) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m computable_tensors:\n\u001b[1;32m-> 1142\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mGraph disconnected: cannot obtain value for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensor \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m at layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1145\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following previous layers were accessed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1146\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwithout issue: \u001b[39m\u001b[39m{\u001b[39;00mlayers_with_complete_input\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1148\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(node\u001b[39m.\u001b[39moutputs):\n\u001b[0;32m   1149\u001b[0m     computable_tensors\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(x))\n",
      "\u001b[1;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 99), dtype=tf.float32, name='input_10'), name='input_10', description=\"created by layer 'input_10'\") at layer \"Encoder\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "encoder_model = tf.keras.models.Model(inputs=clf.layers[0].input,\n",
    "                                      outputs=clf.layers[-2].output)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_model.save('encoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
