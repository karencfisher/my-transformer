{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Flatten\n",
    "\n",
    "from transformer.encoder import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'num_heads': 12, \n",
    "          'vocab_size': 30522,\n",
    "          'hidden_size': 128,\n",
    "          'max_position_embeds': 512,\n",
    "          'intermediate_size': 512,\n",
    "          'dropout_p': 0.1,\n",
    "          'input_size': (100,),\n",
    "          'num_hidden_layers': 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some toy data\n",
    "\n",
    "The yelp sentence sentiment data set from Kaggle will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0                           Wow... Loved this place.          1\n",
       "1                                 Crust is not good.          0\n",
       "2          Not tasty and the texture was just nasty.          0\n",
       "3  Stopped by during the late May bank holiday of...          1\n",
       "4  The selection on the menu was great and so wer...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "with open('yelp_labelled.txt', 'r') as FILE:\n",
    "    while True:\n",
    "        row = FILE.readline()\n",
    "        if not row:\n",
    "            break\n",
    "        row = row.strip().split('\\t')\n",
    "        sentence = row[0]\n",
    "        sentiment = int(row[1])\n",
    "        rows.append({'sentence': sentence, 'sentiment': sentiment})\n",
    " \n",
    "df = pd.DataFrame(rows, columns=['sentence', 'sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our toy vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'<pad>': 0, '<unk>': 1}\n",
    "index = 2\n",
    "for s in df['sentence'].values:\n",
    "    words = s.strip().split()\n",
    "    for word in words:\n",
    "        i = vocab.get(word)\n",
    "        if i is None:\n",
    "            vocab[word] = index\n",
    "            index += 1\n",
    "\n",
    "vocab_reverse = {value: key for key, value in vocab.items()}\n",
    "\n",
    "config['vocab_size'] = len(vocab)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the sentences and split into x and y \n",
    "\n",
    "y will be the last token of each sequence, so we can try to predict it. But mostly we just want to see if our transformer encoder trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1000\n",
      "Vocabulary size: 2971\n",
      "Max sentence length: 31\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sent):\n",
    "    tokens = [vocab[word] for word in sent.strip().split()]\n",
    "    return tokens\n",
    "\n",
    "tokens = list(map(tokenize, df['sentence']))\n",
    "x = [s[:-1] for s in tokens]\n",
    "x = tf.keras.utils.pad_sequences(x)\n",
    "y = np.array([s[-1] for s in tokens])\n",
    "\n",
    "config['input_size'] = (len(x[0]),)\n",
    "\n",
    "print(f'Number of sentences: {df.shape[0]}')\n",
    "print(f'Vocabulary size: {config[\"vocab_size\"]}')\n",
    "print(f'Max sentence length: {config[\"input_size\"][0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our transformer!\n",
    "\n",
    "We'll just train our encoder by the task of predicting the last word of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Encoder (Encoder)           (None, 31, 128)           640232    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3968)              0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 2971)              11791899  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,432,131\n",
      "Trainable params: 12,432,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf = Sequential([InputLayer(input_shape=config['input_size']),\n",
    "                  Encoder(config),\n",
    "                  Flatten(),\n",
    "                  Dense(config['vocab_size'], activation='softmax')])\n",
    "\n",
    "clf.build()\n",
    "clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.2285\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 5.5267\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.1373\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.0923\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.6222\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.6809\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.6765\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.7424\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 1.4399\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.2642\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.3231\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.3622\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.2437\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.0194\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.6608\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 1.0293\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 1.0492\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.6868\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.6761\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.5178\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4991\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4455\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4478\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.3581\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.2441\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1472\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1727\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1835\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0827\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0671\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1088\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1125\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0410\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0419\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0155\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0171\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0611\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0212\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0106\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0114\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0261\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0126\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0070\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0200\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0047\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0058\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0091\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0012\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0031\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.0020\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0012\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0027\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0027\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0018\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0044\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0022\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0053\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0020\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0031\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.9234e-04\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0022\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 7.8403e-04\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 7.4767e-04\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0014\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8779e-04\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0019\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 2.9890e-04\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 6.9595e-04\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.3784e-04\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 9.7171e-04\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.3951e-04\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0012\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 7.0395e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 5.3858e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 5.0212e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 4.6862e-04\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.7394e-04\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 2.2715e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 3.9180e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 3.5566e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.0007e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 2.7120e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.3385e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.2581e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 9.8327e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 2.6586e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 2.6593e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.3249e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 2.6990e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.7965e-04\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.6459e-04\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 2.8941e-04\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.7239e-04\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 2.3116e-04\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 4.1722e-04\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 6.6180e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 7.2838e-04\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.2484e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 4.9770e-04\n"
     ]
    }
   ],
   "source": [
    "clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "hist = clf.fit(x, \n",
    "               y,\n",
    "               epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test our toy model\n",
    "\n",
    "Make up a few sentences that may belong to the distribution (Yelp restaraunt review sentences).\n",
    "\n",
    "Then, dropping off that last word of each, try to complete them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "\n",
      "Original sentence: It really tasted awful.\n",
      "Completed sentence: It really tasted awful.\n",
      "\n",
      "Original sentence: It was very good.\n",
      "Completed sentence: It was very good.\n",
      "\n",
      "Original sentence: It was awful.\n",
      "Completed sentence: It was awful.\n",
      "\n",
      "Original sentence: This is a very bad place.\n",
      "Completed sentence: This is a very bad place.\n",
      "\n",
      "Original sentence: The spaghetti was perfect\n",
      "Completed sentence: The spaghetti was perfect\n",
      "\n",
      "Original sentence: The eggs were gross!\n",
      "Completed sentence: The eggs were gross!\n",
      "\n",
      "Original sentence: My steak was bad.\n",
      "Completed sentence: My steak was bad.\n"
     ]
    }
   ],
   "source": [
    "s = [\"It really tasted awful.\",\n",
    "     \"It was very good.\",\n",
    "     \"It was awful.\",\n",
    "     \"This is a very bad place.\",\n",
    "     \"The spaghetti was perfect\",\n",
    "     \"The eggs were gross!\",\n",
    "     \"My steak was bad.\"]\n",
    "\n",
    "# Tokenize our sentence, separate last word, and pad\n",
    "tokens = list(map(tokenize, s))\n",
    "x = [s[:-1] for s in tokens]\n",
    "x = tf.keras.utils.pad_sequences(x, maxlen=config['input_size'][0])\n",
    "y = np.array([s[-1] for s in tokens])\n",
    "\n",
    "# Predict last word\n",
    "y_hat = clf.predict(x)\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "\n",
    "for i in range(len(s)):\n",
    "     # construct predicted complete sentence\n",
    "     pred_s = x[i].tolist()\n",
    "     pred_s.append(y_hat[i])\n",
    "\n",
    "     #unpad\n",
    "     pred_s = [token for token in pred_s if token!= 0]\n",
    "     pred_s = ' '.join([vocab_reverse[i] for i in pred_s])\n",
    "     print(f'\\nOriginal sentence: {s[i]}\\nCompleted sentence: {pred_s}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trans-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
